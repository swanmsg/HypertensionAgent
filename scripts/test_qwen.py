#!/usr/bin/env python3
"""
é˜¿é‡Œäº‘qwen-plusæ¨¡å‹æµ‹è¯•è„šæœ¬
"""

import os
import sys
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def test_qwen_model():
    """æµ‹è¯•é˜¿é‡Œäº‘qwen-plusæ¨¡å‹"""
    print("ğŸ§ª æµ‹è¯•é˜¿é‡Œäº‘qwen-plusæ¨¡å‹...")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        print("âŒ ç¼ºå°‘DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        print("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®ï¼šDASHSCOPE_API_KEY=your_api_key_here")
        return False
    
    try:
        # å¯¼å…¥å¿…è¦çš„åº“
        from langchain_community.llms import Tongyi
        print("âœ… æˆåŠŸå¯¼å…¥Tongyiç±»")
        
        # åˆå§‹åŒ–æ¨¡å‹
        llm = Tongyi(
            model_name="qwen-plus",
            temperature=0.3,
            max_tokens=500
        )
        print("âœ… æˆåŠŸåˆå§‹åŒ–qwen-plusæ¨¡å‹")
        
        # æµ‹è¯•è°ƒç”¨
        test_prompt = "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹é«˜è¡€å‹çš„å®šä¹‰å’Œåˆ†ç±»ã€‚"
        print(f"ğŸ¤– æµ‹è¯•æç¤º: {test_prompt}")
        
        response = llm(test_prompt)
        print(f"ğŸ“ æ¨¡å‹å›å¤: {response}")
        
        if response and len(response.strip()) > 10:
            print("âœ… qwen-plusæ¨¡å‹æµ‹è¯•æˆåŠŸï¼")
            return True
        else:
            print("âŒ æ¨¡å‹å›å¤ä¸ºç©ºæˆ–è¿‡çŸ­")
            return False
            
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("è¯·å®‰è£…dashscope: pip install dashscope")
        return False
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model_switch():
    """æµ‹è¯•æ¨¡å‹åˆ‡æ¢åŠŸèƒ½"""
    print("\nğŸ”„ æµ‹è¯•æ¨¡å‹åˆ‡æ¢åŠŸèƒ½...")
    
    try:
        from app.services.ai_agent import HypertensionAgent
        print("âœ… æˆåŠŸå¯¼å…¥HypertensionAgent")
        
        # åˆ›å»ºæ™ºèƒ½ä½“
        agent = HypertensionAgent()
        print("âœ… æˆåŠŸåˆ›å»ºæ™ºèƒ½ä½“å®ä¾‹")
        
        # è·å–æ¨¡å‹ä¿¡æ¯
        model_info = agent.get_model_info()
        print(f"ğŸ“Š å½“å‰æ¨¡å‹ä¿¡æ¯: {model_info}")
        
        if model_info.get('status') == 'online':
            print("âœ… æ¨¡å‹çŠ¶æ€æ­£å¸¸")
            
            # æµ‹è¯•ç®€å•å¯¹è¯
            test_question = "ä»€ä¹ˆæ˜¯é«˜è¡€å‹ï¼Ÿ"
            response = agent.chat(test_question)
            
            if "æŠ±æ­‰" not in response and "å¤±è´¥" not in response:
                print("âœ… å¯¹è¯åŠŸèƒ½æµ‹è¯•æˆåŠŸ")
                print(f"ğŸ¤– AIå›å¤æ‘˜è¦: {response[:100]}...")
                return True
            else:
                print(f"âŒ å¯¹è¯æµ‹è¯•å¤±è´¥: {response}")
                return False
        else:
            print("âŒ æ¨¡å‹çŠ¶æ€å¼‚å¸¸")
            return False
            
    except Exception as e:
        print(f"âŒ æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¥ é˜¿é‡Œäº‘qwen-plusæ¨¡å‹æµ‹è¯•")
    print("=" * 50)
    
    success_count = 0
    total_tests = 2
    
    # æµ‹è¯•1: åŸºç¡€æ¨¡å‹è°ƒç”¨
    if test_qwen_model():
        success_count += 1
    
    # æµ‹è¯•2: æ™ºèƒ½ä½“é›†æˆ
    if test_model_switch():
        success_count += 1
    
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 50)
    print(f"é€šè¿‡æµ‹è¯•: {success_count}/{total_tests}")
    
    if success_count == total_tests:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼qwen-plusæ¨¡å‹é…ç½®æˆåŠŸã€‚")
        print("\nğŸ“‹ ä¸‹ä¸€æ­¥:")
        print("1. ç¡®ä¿.envæ–‡ä»¶ä¸­è®¾ç½®äº† LLM_PROVIDER=qwen-plus")
        print("2. è¿è¡Œ python run.py dev å¯åŠ¨å®Œæ•´æœåŠ¡")
        return True
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
        print("\nğŸ”§ æ’æŸ¥å»ºè®®:")
        print("1. ç¡®è®¤DASHSCOPE_API_KEYæ­£ç¡®è®¾ç½®")
        print("2. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("3. ç¡®è®¤é˜¿é‡Œäº‘è´¦æˆ·ä½™é¢å……è¶³")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)